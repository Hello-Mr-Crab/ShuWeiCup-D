{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################数据预处理###################\n",
    "#缺失值剔除并按照行政区域划分\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.unicode.ambiguous_as_wide', True)\n",
    "pd.set_option('display.unicode.east_asian_width', True)\n",
    "pd.set_option('display.width', 300)\n",
    "pd.set_option(\"display.max_rows\",10000)\n",
    "pd.set_option(\"display.max_columns\",50)\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "city1=pd.read_excel(r\"E:\\OneDrive\\Desktop\\2024_“ShuWei Cup”D_Problem\\Appendix 1.xlsx\",sheet_name=\"Sheet1\")\n",
    "city1=city1.dropna()#缺失值剔除\n",
    "city2=pd.read_excel(r\"E:\\OneDrive\\Desktop\\2024_“ShuWei Cup”D_Problem\\Appendix 2.xlsx\",sheet_name=\"Sheet1\")\n",
    "city2=city2.dropna()#缺失值剔除\n",
    "city1['adcode']=city1['adcode'].astype(str)#将行政区#域转型为字符串便于新建eccel时命名sheet_name\n",
    "city2['adcode']=city2['adcode'].astype(str)#将行政区#域转型为字符串便于新建eccel时命名sheet_name\n",
    "city1_adcode=list(set(city1['adcode']))#利用集合去重性质获得所有行政区域代码\n",
    "city2_adcode=list(set(city2['adcode']))#\n",
    "\n",
    "#将原数据中不同区域的房价信息导入到每一页上,每一页的sheet_name为该区的行政代码\n",
    "with pd.ExcelWriter(\"E:\\OneDrive\\Desktop\\city1.xlsx\", mode='a', engine='openpyxl') as writer:\n",
    "    for adcode in city1_adcode:\n",
    "        district_data=city1[city1['adcode']==adcode]\n",
    "        district_data.to_excel(writer,sheet_name=adcode)\n",
    "        print(f\"{adcode}区房价基本面数据已导入到city1.xlsx第{adcode}页\")\n",
    "\n",
    "#将原数据中不同区域的房价信息导入到每一页上,每一页的sheet_name为该区的行政代码\n",
    "with pd.ExcelWriter(\"city2.xlsx\", mode='a', engine='openpyxl') as writer:\n",
    "    for adcode in city2_adcode:\n",
    "        district_data=city2[city2['adcode']==adcode]\n",
    "        district_data.to_excel(writer,sheet_name=adcode)\n",
    "        print(f\"{adcode}区房价基本面数据已导入到city2.xlsx第{adcode}页\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from 回归模型 import xgboost回归\n",
    "pd.set_option('display.unicode.ambiguous_as_wide', True)\n",
    "pd.set_option('display.unicode.east_asian_width', True)\n",
    "pd.set_option('display.width', 300)\n",
    "pd.set_option(\"display.max_rows\",10000)\n",
    "pd.set_option(\"display.max_columns\",50)\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "city1=pd.read_excel(\"city1.xlsx\")\n",
    "city2=pd.read_excel(\"city2.xlsx\")\n",
    "city2_adcode=[150119,150102,150103,150121,150105,150104,150172,150123]#city1内各个行政区域\n",
    "city1_adcode=[220102, 220103, 220104, 220105, 220106, 220171, 220172, 220173, 220174, 220112, 220113, 220182, 220183, 220122]#city2内各个行政区域\n",
    "mean_prices_in_different_district_in_city1=[]\n",
    "mean_prices_in_different_district_in_city2=[]\n",
    "for adcode in city1_adcode:\n",
    "    city1_mean_price=round(pd.read_excel(\"city1.xlsx\",sheet_name=str(adcode))['Price (USD)'].mean(),2)\n",
    "    mean_prices_in_different_district_in_city1.append(city1_mean_price)\n",
    "for adcode in city2_adcode:\n",
    "    city2_mean_price=round(pd.read_excel(\"city2.xlsx\",sheet_name=str(adcode))['Price (USD)'].mean(),2)\n",
    "    mean_prices_in_different_district_in_city2.append(city2_mean_price)\n",
    "# data=pd.read_excel(\"城市1 人口GDP.xlsx\",sheet_name=\"Sheet1\")\n",
    "# GDP=dict(zip(data['行政区划代码'],data['GDP（亿元）']))\n",
    "# Population=dict(zip(data['行政区划代码'],data['人口']))\n",
    "# GDP=[GDP.get(adcode)*10000000 for adcode in city1_adcode]\n",
    "# Population=[Population.get(adcode) for adcode in city1_adcode]\n",
    "# city1_data={\"行政区划代码\":city1_adcode,\"GDP\":GDP,\"人口\":Population,\"房价均值\":mean_prices_in_different_district_in_city1}\n",
    "# city1_data=pd.DataFrame(city1_data,columns=[\"行政区划代码\",\"GDP\",\"人口\",\"房价均值\"],index=range(1,15))\n",
    "# city1_data.to_excel(\"city1_data.xlsx\")\n",
    "data=pd.read_excel(\"city1_data.xlsx\")[[\"GDP\",\"人口\",\"房价均值\"]]\n",
    "x=pd.read_excel(\"city1_data.xlsx\")[\"人口\"]\n",
    "y=pd.read_excel(\"city1_data.xlsx\")['房价均值']\n",
    "xgboost回归(x=x,y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制两城市房价分布直方图\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "city2=pd.read_excel(r\"E:\\OneDrive\\Desktop\\数维杯\\附录文件\\correct_Append2.xlsx\")[[\"Price (USD)\",\"Total number of households\",\"Greening rate\",\"Floor area ratio\"]]\n",
    "city1=pd.read_excel(r\"E:\\OneDrive\\Desktop\\数维杯\\附录文件\\correct_Append1.xlsx\")[[\"Price (USD)\",\"Total number of households\",\"Greening rate\",\"Floor area ratio\"]]\n",
    "plt.figure(dpi=80),sns.histplot(city1[\"Price (USD)\"],kde=True,color=\"green\"),plt.title(\"Price Distribution\"),plt.gca().set_facecolor(\"white\"),plt.show()\n",
    "plt.figure(dpi=80),sns.histplot(city2[\"Price (USD)\"],kde=True,color=\"green\"),plt.title(\"Price Distribution\"),plt.gca().set_facecolor(\"white\"),plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#相关性分析\n",
    "import pandas as pd\n",
    "from python绘图 import 热力图\n",
    "from 特征工程 import 相关性分析\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "city2=pd.read_excel(r\"E:\\OneDrive\\Desktop\\数维杯\\附录文件\\correct_Append2.xlsx\")[[\"Price (USD)\",\"Total number of households\",\"Greening rate\",\"Floor area ratio\",\"Property management fee\",\"above-ground parking fee（/month USD）\",\"underground parking fee（/month USD）\"]]\n",
    "city1=pd.read_excel(r\"E:\\OneDrive\\Desktop\\数维杯\\附录文件\\correct_Append1.xlsx\")[[\"Price (USD)\",\"Total number of households\",\"Greening rate\",\"Floor area ratio\",\"Property management fee\",\"above-ground parking fee（/month USD）\",\"underground parking fee（/month USD）\"]]\n",
    "scaler=StandardScaler()\n",
    "city2_standardized=scaler.fit_transform(city2)\n",
    "city2_standardized=pd.DataFrame(city2_standardized,columns=city2.columns)\n",
    "matrix=city2_standardized.corr(method=\"pearson\",numeric_only=True)\n",
    "heatmap=热力图(matrix,dpi=80,颜色=\"coolwarm_r\",图片大小=(6,6),x轴标签=city2.columns,y轴标签=city2.columns,标题=\"Pearson correlation coefficient heat map\")\n",
    "heatmap.标题文本设置(字体参数={\"size\":15,\"color\":\"#ff8066\"})\n",
    "heatmap.y轴标签设置(字体参数={\"size\":12,\"rotation\":10})\n",
    "heatmap.x轴标签设置(字体参数={\"size\":12,\"rotation\":80})\n",
    "heatmap.绘制()\n",
    "\n",
    "city1_standardized=scaler.fit_transform(city1)\n",
    "city1_standardized=pd.DataFrame(city1_standardized,columns=city1.columns)\n",
    "matrix=city1_standardized.corr(method=\"pearson\",numeric_only=True)\n",
    "heatmap=热力图(matrix,dpi=80,颜色=\"cubehelix_r\",图片大小=(6,6),x轴标签=city1.columns,y轴标签=city1.columns,标题=\"Pearson correlation coefficient heat map\")\n",
    "heatmap.标题文本设置(字体参数={\"size\":15,\"color\":\"#c34a36\"})\n",
    "heatmap.y轴标签设置(字体参数={\"size\":12,\"rotation\":10})\n",
    "heatmap.x轴标签设置(字体参数={\"size\":12,\"rotation\":80})\n",
    "heatmap.绘制()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#计算住房存量\n",
    "city2_adcode=[150119,150102,150103,150121,150105,150104,150172,150123]#city1内各个行政区域\n",
    "city1_adcode=[220102, 220103, 220104, 220105, 220106, 220171, 220172, 220173, 220174, 220112, 220113, 220182, 220183, 220122]#city2内各个行政区域\n",
    "city1_Density=dict(zip(city1_adcode,pd.read_excel(\"city1_data.xlsx\",sheet_name=\"Sheet1\")[\"居住密度\"]))\n",
    "city2_Density=dict(zip(city2_adcode,pd.read_excel(\"city2_data.xlsx\",sheet_name=\"Sheet1\")[\"居住密度\"]))\n",
    "with pd.ExcelWriter(\"city1_new.xlsx\", mode='a', engine='openpyxl') as writer:#在cit1.xlsx基础上每一页/每一行政区内加一行House stock存到city1_new.xlsx里\n",
    "    for adcode in city1_adcode:\n",
    "        city1=pd.read_excel(\"city1.xlsx\",sheet_name=str(adcode))\n",
    "        city1[\"House Stock\"]=round(city1[\"Total number of households\"]*(1+city1_Density.get(adcode)/city1[\"Floor area ratio\"]),0)\n",
    "        city1.to_excel(writer,sheet_name=str(adcode))\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(\"city2_new.xlsx\", mode='a', engine='openpyxl') as writer:#在cit2.xlsx基础上每一页/每一行政区内加一行House stock存到city2_new.xlsx里\n",
    "    for adcode in city2_adcode:\n",
    "        city2=pd.read_excel(\"city2.xlsx\",sheet_name=str(adcode))\n",
    "        city2[\"House Stock\"]=round(city2[\"Total number of households\"]*(1+city2_Density.get(adcode)/city2[\"Floor area ratio\"]),0)\n",
    "        city2.to_excel(writer,sheet_name=str(adcode))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "city2_adcode=[150119,150102,150103,150121,150105,150104,150172,150123]#city1内各个行政区域\n",
    "city1_adcode=[220102, 220103, 220104, 220105, 220106, 220171, 220172, 220173, 220174, 220112, 220113, 220182, 220183, 220122]#city2内各个行政区域\n",
    "sum_house_stock_in_city1=[]\n",
    "sum_house_stock_in_city2=[]\n",
    "city1_data=pd.read_excel(\"city1_data.xlsx\",sheet_name=\"Sheet1\")\n",
    "city2_data=pd.read_excel(\"city2_data.xlsx\",sheet_name=\"Sheet1\")\n",
    "for adcode in city1_adcode:\n",
    "    city1=pd.read_excel(\"city1.xlsx\",sheet_name=str(adcode))[\"House Stock\"]\n",
    "    sum_house_stock_in_city1.append(city1.sum())\n",
    "for adcode in city2_adcode:\n",
    "    city2=pd.read_excel(\"city2.xlsx\",sheet_name=str(adcode))[\"House Stock\"]\n",
    "    sum_house_stock_in_city2.append(city2.sum())\n",
    "city1_data[\"住房存量\"]=sum_house_stock_in_city1\n",
    "city2_data[\"住房存量\"]=sum_house_stock_in_city2\n",
    "city1_data.to_excel(\"city1_data.xlsx\")\n",
    "city2_data.to_excel(\"city2_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "a=pd.read_csv(r\"E:\\OneDrive\\Desktop\\2024_“ShuWei Cup”D_Problem\\Appendix 3\\Public facilities data.csv\")\n",
    "plt.scatter(a[\"lon_gcj02\"],a[\"lat_gcj02\\r\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "car_data1=pd.read_csv(r\"E:\\OneDrive\\Desktop\\2024_“ShuWei Cup”D_Problem\\Appendix 4\\Public facilities data.csv\",encoding='utf-8')\n",
    "print(car_data1[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制各个部门分布图\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "def get_files_in_folder(folder_path):\n",
    "    files=os.listdir(folder_path)\n",
    "    files=[os.path.join(folder_path,path) for path in files]\n",
    "    return files\n",
    "city1_data=get_files_in_folder(\"Appendix 3\")\n",
    "plt.figure(dpi=300)\n",
    "sector1=pd.read_csv(city1_data[0])\n",
    "plt.scatter(sector1[\"lon_gcj02\"],sector1[\"lat_gcj02\\r\"],s=4,marker=\"*\",label=city1_data[0].replace(\"Appendix 3\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector2=pd.read_csv(city1_data[1])\n",
    "plt.scatter(sector2[\"lon_gcj02\"],sector2[\"lat_gcj02\\r\"],s=4,marker=\"o\",label=city1_data[1].replace(\"Appendix 3\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector3=pd.read_csv(city1_data[2])\n",
    "plt.scatter(sector3[\"lon_gcj02\"],sector3[\"lat_gcj02\\r\"],s=4,marker=\"v\",label=city1_data[2].replace(\"Appendix 3\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector4=pd.read_csv(city1_data[3])\n",
    "plt.scatter(sector4[\"lon_gcj02\"],sector4[\"lat_gcj02\\r\"],s=4,marker=\"8\",label=city1_data[3].replace(\"Appendix 3\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector5=pd.read_csv(city1_data[4])\n",
    "plt.scatter(sector5[\"lon_gcj02\"],sector5[\"lat_gcj02\\r\"],s=4,marker=\"s\",label=city1_data[4].replace(\"Appendix 3\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector6=pd.read_csv(city1_data[5])\n",
    "plt.scatter(sector6[\"lon_gcj02\"],sector6[\"lat_gcj02\\r\"],s=4,marker=\"p\",label=city1_data[5].replace(\"Appendix 3\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector7=pd.read_csv(city1_data[6])\n",
    "plt.scatter(sector7[\"lon_gcj02\"],sector7[\"lat_gcj02\\r\"],s=4,marker=\"h\",label=city1_data[6].replace(\"Appendix 3\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector8=pd.read_csv(city1_data[7])\n",
    "plt.scatter(sector8[\"lon_gcj02\"],sector8[\"lat_gcj02\\r\"],s=4,marker=\"D\",label=city1_data[7].replace(\"Appendix 3\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector9=pd.read_csv(city1_data[8])\n",
    "plt.scatter(sector9[\"lon_gcj02\"],sector9[\"lat_gcj02\\r\"],s=4,marker=\",\",label=city1_data[8].replace(\"Appendix 3\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector10=pd.read_csv(city1_data[9])\n",
    "plt.scatter(sector10[\"lon_gcj02\"],sector10[\"lat_gcj02\\r\"],s=4,marker=\"3\",label=city1_data[9].replace(\"Appendix 3\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector11=pd.read_csv(city1_data[10])\n",
    "plt.scatter(sector11[\"lon_gcj02\"],sector11[\"lat_gcj02\\r\"],s=4,marker=\"2\",label=city1_data[10].replace(\"Appendix 3\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector12=pd.read_csv(city1_data[11])\n",
    "plt.scatter(sector12[\"lon_gcj02\"],sector12[\"lat_gcj02\\r\"],s=4,marker=\"1\",label=city1_data[11].replace(\"Appendix 3\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector13=pd.read_csv(city1_data[12])\n",
    "plt.scatter(sector13[\"lon_gcj02\"],sector13[\"lat_gcj02\\r\"],s=4,marker=\"+\",label=city1_data[12].replace(\"Appendix 3\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector14=pd.read_csv(city1_data[13])\n",
    "plt.scatter(sector14[\"lon_gcj02\"],sector14[\"lat_gcj02\\r\"],s=4,marker=\"d\",label=city1_data[13].replace(\"Appendix 3\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector15=pd.read_csv(city1_data[14])\n",
    "plt.scatter(sector15[\"lon_gcj02\"],sector15[\"lat_gcj02\\r\"],s=4,marker=\"x\",label=city1_data[14].replace(\"Appendix 3\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "plt.scatter(125.352222,43.885556,marker=\"+\",s=80,color=\"red\",label='City Center')\n",
    "plt.title(\"Sectors Distribution\")\n",
    "plt.legend(prop={\"size\":5},loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"longituide\")\n",
    "plt.ylabel(\"latitude\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制各个部门分布图\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_files_in_folder(folder_path):\n",
    "    files=os.listdir(folder_path)\n",
    "    files=[os.path.join(folder_path,path) for path in files]\n",
    "    return files\n",
    "city2_data=get_files_in_folder(\"Appendix 4\")\n",
    "plt.figure(dpi=200)\n",
    "sector1=pd.read_csv(city2_data[0],encoding=\"gbk\")\n",
    "plt.scatter(sector1[\"lon_gcj02\"],sector1[\"lat_gcj02\"],s=4,marker=\"*\",label=city2_data[0].replace(\"Appendix 4\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector2=pd.read_csv(city2_data[1],encoding=\"gbk\")\n",
    "plt.scatter(sector2[\"lon_gcj02\"],sector2[\"lat_gcj02\"],s=4,marker=\"o\",label=city2_data[1].replace(\"Appendix 4\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector3=pd.read_csv(city2_data[2],encoding=\"gbk\")\n",
    "plt.scatter(sector3[\"lon_gcj02\"],sector3[\"lat_gcj02\"],s=4,marker=\"v\",label=city2_data[2].replace(\"Appendix 4\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector4=pd.read_csv(city2_data[3],encoding=\"gbk\")\n",
    "plt.scatter(sector4[\"lon_gcj02\"],sector4[\"lat_gcj02\"],s=4,marker=\"8\",label=city2_data[3].replace(\"Appendix 4\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector5=pd.read_csv(city2_data[4],encoding=\"gbk\")\n",
    "plt.scatter(sector5[\"lon_gcj02\"],sector5[\"lat_gcj02\"],s=4,marker=\"s\",label=city2_data[4].replace(\"Appendix 4\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector6=pd.read_csv(city2_data[5],encoding=\"gbk\")\n",
    "plt.scatter(sector6[\"lon_gcj02\"],sector6[\"lat_gcj02\"],s=4,marker=\"p\",label=city2_data[5].replace(\"Appendix 4\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector7=pd.read_csv(city2_data[6],encoding=\"gbk\")\n",
    "plt.scatter(sector7[\"lon_gcj02\"],sector7[\"lat_gcj02\"],s=4,marker=\"h\",label=city2_data[6].replace(\"Appendix 4\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector8=pd.read_csv(city2_data[7],encoding=\"gbk\")\n",
    "plt.scatter(sector8[\"lon_gcj02\"],sector8[\"lat_gcj02\"],s=4,marker=\"D\",label=city2_data[7].replace(\"Appendix 4\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector9=pd.read_csv(city2_data[8],encoding=\"gbk\")\n",
    "plt.scatter(sector9[\"lon_gcj02\"],sector9[\"lat_gcj02\"],s=4,marker=\",\",label=city2_data[8].replace(\"Appendix 4\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector10=pd.read_csv(city2_data[9],encoding=\"gbk\")\n",
    "plt.scatter(sector10[\"lon_gcj02\"],sector10[\"lat_gcj02\"],s=4,marker=\"3\",label=city2_data[9].replace(\"Appendix 4\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector11=pd.read_csv(city2_data[10],encoding=\"gbk\")\n",
    "plt.scatter(sector11[\"lon_gcj02\"],sector11[\"lat_gcj02\"],s=4,marker=\"2\",label=city2_data[10].replace(\"Appendix 4\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector12=pd.read_csv(city2_data[11],encoding=\"gbk\")\n",
    "plt.scatter(sector12[\"lon_gcj02\"],sector12[\"lat_gcj02\"],s=4,marker=\"1\",label=city2_data[11].replace(\"Appendix 4\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector13=pd.read_csv(city2_data[12],encoding=\"gbk\")\n",
    "plt.scatter(sector13[\"lon_gcj02\"],sector13[\"lat_gcj02\"],s=4,marker=\"+\",label=city2_data[12].replace(\"Appendix 4\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector14=pd.read_csv(city2_data[13],encoding=\"gbk\")\n",
    "plt.scatter(sector14[\"lon_gcj02\"],sector14[\"lat_gcj02\"],s=4,marker=\"d\",label=city2_data[13].replace(\"Appendix 4\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "sector15=pd.read_csv(city2_data[14],encoding=\"gbk\")\n",
    "plt.scatter(sector15[\"lon_gcj02\"],sector15[\"lat_gcj02\"],s=4,marker=\"x\",label=city2_data[14].replace(\"Appendix 4\\\\\",\"\").replace(\".csv\",\"\"))\n",
    "plt.scatter(111.41,40.48,marker=\"+\",s=120,color=\"blue\",label='City Center')\n",
    "plt.title(\"Sectors Distribution\")\n",
    "plt.legend(prop={\"size\":5},loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"longituide\")\n",
    "plt.ylabel(\"latitude\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    指标  医疗卫生保障  紧急避难场所设施  政府组织能力  运输能力  应急物品保障  人均GDP  人口密度  社会保障资金   评分\n",
      "0  城市1        0.7526            0.9806        0.6130    0.7008        0.7433   0.5846    0.7630        0.7392  75.61\n",
      "1  城市2        0.6585            0.1961        0.7901    0.7133        0.6690   0.8113    0.6464        0.6735  24.39\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"font.sans-serif\"]=[\"SimHei\"]\n",
    "pd.set_option('display.unicode.ambiguous_as_wide', True)\n",
    "pd.set_option('display.unicode.east_asian_width', True)\n",
    "pd.set_option('display.width', 300)\n",
    "pd.set_option(\"display.max_rows\",10000)\n",
    "pd.set_option(\"display.max_columns\",50)\n",
    "city1_index1=[]\n",
    "city1_index2=[]\n",
    "city1_index3=[]\n",
    "city2_index1=[]\n",
    "city2_index2=[]\n",
    "city2_index3=[]\n",
    "'''优化算法计算BWM权重'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "pd.set_option('display.unicode.ambiguous_as_wide', True)\n",
    "pd.set_option('display.unicode.east_asian_width', True)\n",
    "pd.set_option('display.width', 280)\n",
    "pd.set_option(\"display.max_rows\",1000)\n",
    "pd.set_option(\"display.max_columns\",50)\n",
    "# def generating_initial_weight(criterion_num):\n",
    "#     weight=np.zeros(criterion_num)\n",
    "#     random_sequence=np.random.rand(criterion_num)\n",
    "#     for i in range(criterion_num):\n",
    "#           weight[i]=np.around(random_sequence[i]/np.sum(random_sequence),2)\n",
    "#     return weight\n",
    "# def generating_new_weight(weight):\n",
    "#     weight[best_index]+=0.01\n",
    "#     weight[worst_index]-=0.01\n",
    "#     return weight\n",
    "# def fitness_function(weight):\n",
    "#     epsilon1=[]\n",
    "#     epsilon2=[]\n",
    "#     for i in range(len(weight)):\n",
    "#             epsilon1.append(abs(weight[best_index]/weight[i]-BO[i]))\n",
    "#     for j in range(len(weight)):\n",
    "#             epsilon2.append(abs(weight[j]/weight[worst_index]-OW[j]))\n",
    "#     epsilon1_max=min(epsilon1)\n",
    "#     epsilon2_max=min(epsilon2)\n",
    "#     return max(epsilon1_max,epsilon2_max)\n",
    "    \n",
    "# class 模拟退火算法():\n",
    "#     def __init__(self,size,initial_solution,cooling_rate=0.95,initial_temperature=200,max_iterations=200):\n",
    "#         self.cooling_rate=cooling_rate#冷却系数\n",
    "#         self.initial_temperature=initial_temperature#初始温度\n",
    "#         self.initial_solution=initial_solution#初始解，一般为列表随机编号\n",
    "#         self.current_solution=initial_solution#当前解\n",
    "#         self.best_solution=initial_solution#最优解\n",
    "#         self.max_iterations=max_iterations#最大迭代次数\n",
    "#         self.size=size#初始解的大小\n",
    "#     def 目标函数(self,weight):\n",
    "#         #根据实际问题，自行编写\n",
    "#         return fitness_function(weight)\n",
    "#     def 约束条件(self,solution):#对初始解代入以后的目标函数值进行约束\n",
    "#         pass\n",
    "             \n",
    "#     def 模拟退火(self):\n",
    "#         self.temperature=self.initial_temperature\n",
    "#         record=[]\n",
    "#         iterations=[]\n",
    "#         self.current_目标函数值=self.best_目标函数值=self.目标函数(self.current_solution)\n",
    "#         for iteration in range(self.max_iterations):\n",
    "#                 new_solution = self.current_solution.copy()\n",
    "               \n",
    "#                 new_solution=generating_new_weight(new_solution)\n",
    "#                 if new_solution[worst_index]!=0:#这里可以改成self.约束条件(new_solution)#如果没有表就默认无约束条件\n",
    "#                     self.new_目标函数值 = self.目标函数(new_solution)\n",
    "#                     self.delta_目标函数值 = self.new_目标函数值 - self.current_目标函数值\n",
    "#                     if self.delta_目标函数值 < 0 or np.random.rand()<np.exp(-self.delta_目标函数值/self.temperature):#metroplois准则\n",
    "#                         self.current_solution = new_solution\n",
    "#                         self.current_目标函数值 = self.new_目标函数值\n",
    "#                         if self.new_目标函数值 < self.best_目标函数值:#根据需要修改,小于号求最小最优解,大于号求最大最优解\n",
    "#                             self.best_solution = new_solution\n",
    "#                             self.best_目标函数值 = self.new_目标函数值\n",
    "#                     self.temperature*=self.cooling_rate\n",
    "#                     record.append(self.best_目标函数值)\n",
    "#                     iterations.append(iteration)                  \n",
    "#                 else:\n",
    "#                     pass\n",
    "                \n",
    "#         print(self.best_solution,self.best_目标函数值)\n",
    "#         plt.figure(dpi=150)\n",
    "#         plt.plot(iterations,record)\n",
    "#         plt.title(\"fitness loss\")\n",
    "#         plt.show()\n",
    "#         return self.best_solution\n",
    "# def caluate_weight_by_entrophy_method(data):  #dataframe型数据根据熵权法计算权重                                                              #熵权法求指标权重\n",
    "#         e=[]\n",
    "#         for i in range(data.shape[0]):\n",
    "#             for j in range(data.shape[1]):\n",
    "#                 e.append(round(data.iloc[i,j],4))\n",
    "#         m=np.array(e).reshape(data.shape[0],data.shape[1])\n",
    "#         p=m/m.sum(axis=0)\n",
    "#         E=np.nansum((-p*np.log(p+1e-7))/(np.log(len(p))),axis=0)\n",
    "#         weight=(1-E)/(1-E).sum()\n",
    "#         return np.around(weight,3)\n",
    "\n",
    "def sum_of_square(list):\n",
    "    sum=0\n",
    "    for ele in list.values:\n",
    "        sum+=pow(ele,2)\n",
    "    return sum**0.5\n",
    "\n",
    "def standard(self):\n",
    "        e=[]\n",
    "        sum=[]\n",
    "        name_of_data_index=input(\"请输入数据中标签那一列的名字:\")\n",
    "        data_index=self [name_of_data_index]\n",
    "        indexs=list(self.columns)\n",
    "        self=self.drop(name_of_data_index,axis=1)\n",
    "        for j in self.columns:\n",
    "            sum.append(sum_of_square(self[j]))\n",
    "        for i in range(self.shape[0]):\n",
    "            for j in range(self.shape[1]):\n",
    "                e.append(np.around((self.iloc[i,j])/sum[j],4))\n",
    "        h=pd.DataFrame(np.array(e).reshape(self.shape[0],self.shape[1]))\n",
    "        h.insert(0,name_of_data_index,data_index)\n",
    "        h.columns=indexs\n",
    "        return h\n",
    "def caluate_weight_by_entrophy_method(self):                                                                #熵权法求指标权重\n",
    "    e=[]\n",
    "    for i in range(self.shape[0]):\n",
    "        for j in range(self.shape[1]):\n",
    "            e.append(round(self.iloc[i,j],4))\n",
    "    m=np.array(e).reshape(self.shape[0],self.shape[1])\n",
    "    p=m/m.sum(axis=0)\n",
    "    E=np.nansum((-p*np.log(p+1e-7))/(np.log(len(p))),axis=0)\n",
    "    weight=(1-E)/(1-E).sum()\n",
    "    return np.around(weight,3)\n",
    "  \n",
    "def evalute_score(self):\n",
    "    Score=[]\n",
    "    final_score=[]                                                                                            #熵权法\n",
    "    name_of_data_index=input(\"请输入数据中标签那一列的名字:\")\n",
    "    data_index=self[name_of_data_index]\n",
    "    indexs=list(self.columns)\n",
    "    self=self.drop(name_of_data_index,axis=1)\n",
    "    max_self=[]\n",
    "    min_self=[]\n",
    "    for i in self.columns:\n",
    "        max_self.append(max(self[i]))\n",
    "        min_self.append(min(self[i]))\n",
    "    weight=[0.1764,0.1725,0.1972,0.1255,0.0769,0.1033,0.1482,0.1200]\n",
    "    for i in range(self.shape[0]):\n",
    "        distance_between_min=0\n",
    "        distance_between_max=0\n",
    "        for j in range(self.shape[1]):\n",
    "              distance_between_min+=weight[j]*pow((min_self[j]-self.iloc[i,j]),2)\n",
    "              distance_between_max+=weight[j]*pow((max_self[j]-self.iloc[i,j]),2)\n",
    "        score=pow(distance_between_min,0.5)/(pow(distance_between_min,0.5)+pow(distance_between_max,0.5))\n",
    "        Score.append(score)\n",
    "    for ele in Score:\n",
    "        final_score.append(round((ele/sum(Score)),4))\n",
    "    final_score=np.array(final_score)\n",
    "    self[\"评分\"]=np.array(final_score)*100\n",
    "    self.insert(0,name_of_data_index,data_index)\n",
    "    # self[\"评分\"]=(10/(max(final_score)-min(final_score)))*(self[\"评分\"]-min(final_score))+0\n",
    "    self=self.sort_values(by=\"评分\" ,ascending=False) \n",
    "    return self\n",
    "\n",
    "def get_files_in_folder(folder_path):\n",
    "    files=os.listdir(folder_path)\n",
    "    files=[os.path.join(folder_path,path) for path in files]\n",
    "    return files\n",
    "def calculate_city1(data):\n",
    "    for i in range(15):\n",
    "        data=pd.read_csv(city1_data[i])\n",
    "        city1_index1.append(data.shape[0]/24590)\n",
    "        city1_index2.append(len(set(data[\"adcode\"]))/11)\n",
    "        city1_index3.append(len(set(data[\"typecode\"])))\n",
    "    dataframe={\"部门\":[f\"部门{i+1}\" for i in range(15)],\"分布密度\":city1_index1,\"行业类型丰富度\":city1_index3,\"覆盖率\":city1_index2}\n",
    "    dataframe=pd.DataFrame(dataframe)\n",
    "    return dataframe\n",
    "\n",
    "def calculate_city2(data):\n",
    "    for i in range(15):\n",
    "        data=pd.read_csv(city2_data[i],encoding=\"gbk\")\n",
    "        city2_index1.append(data.shape[0]/17200)\n",
    "        city2_index2.append(len(set(data[\"adcode\"]))/9)\n",
    "        city2_index3.append(len(set(data[\"typecode\"])))\n",
    "    dataframe={\"部门\":[f\"部门{i+1}\" for i in range(15)],\"分布密度\":city2_index1,\"行业类型丰富度\":city2_index3,\"覆盖率\":city2_index2}\n",
    "    dataframe=pd.DataFrame(dataframe)\n",
    "    return dataframe\n",
    "\n",
    "# criterion_num=int(input('请输入准则个数：'))\n",
    "# BO=list(map(int,input('请输入BO:').split(',')))\n",
    "# OW=list(map(int,input('请输入OW:').split(',')))\n",
    "# best_index=BO.index(min(BO))\n",
    "# worst_index=OW.index(max(OW))\n",
    "# print(BO,best_index)\n",
    "# print(OW,worst_index)\n",
    "# weight=generating_initial_weight(criterion_num)\n",
    "# 模拟退火算法(size=3,initial_solution=weight).模拟退火()\n",
    "# city1_data=get_files_in_folder(\"Appendix 3\")\n",
    "# city2_data=get_files_in_folder(\"Appendix 4\")\n",
    "# data1=calculate_city1(city1_data)\n",
    "# data2=calculate_city2(city2_data)\n",
    "#data1=pd.read_excel(\"城市韧性与可持续发展能力.xlsx\",sheet_name='Sheet2')\n",
    "data2=pd.read_excel(\"城市韧性与可持续发展能力.xlsx\",sheet_name=\"Sheet1\")\n",
    "# data1=standard(data1)\n",
    "#data1=evalute_score(data1)\n",
    "data2=standard(data2)\n",
    "data2=evalute_score(data2)\n",
    "# print(data1)\n",
    "print(data2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.000000\n",
      "1    0.355427\n",
      "2    0.483821\n",
      "3    0.381548\n",
      "4    0.388343\n",
      "5    0.285044\n",
      "6    0.253695\n",
      "7    0.140913\n",
      "Name: 可持续发展能力, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# data=pd.read_excel(\"计算韧性指数.xlsx\",sheet_name=\"Sheet2\")\n",
    "# data[\"城市韧性\"]=data[\"Density\"]*0.5/data[\"Density\"].max()+(1-data[\"Diversity\"]/data[\"Diversity\"].max())*0.5\n",
    "# print(data[\"城市韧性\"])\n",
    "\n",
    "import pandas as pd\n",
    "data=pd.read_excel(\"计算可持续发展能力.xlsx\",sheet_name=\"Sheet\")\n",
    "data[\"可持续发展能力\"]=(1-data[\"Density\"]/data[\"Density\"].max())**0.5*(data[\"Diversity\"]/data[\"Diversity\"].max())**0.5\n",
    "print(data[\"可持续发展能力\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=pd.read_excel(\"计算韧性指数.xlsx\",sheet_name=\"Sheet2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
